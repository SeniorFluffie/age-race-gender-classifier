{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd00023c4fd5f676363117a29e544d3fd2bd6574dda579981c548df1caf5d07c58a",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0023c4fd5f676363117a29e544d3fd2bd6574dda579981c548df1caf5d07c58a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, Add, Reshape, DepthwiseConv2D,Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "class MuiltiMobileModel():\n",
    "    def _make_divisible(self, v, divisor, min_value=None):\n",
    "        if min_value is None:\n",
    "            min_value = divisor\n",
    "        new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_v < 0.9 * v:\n",
    "            new_v += divisor\n",
    "        return new_v\n",
    "\n",
    "\n",
    "    def relu6(self, x):\n",
    "        \"\"\"Relu 6\n",
    "        \"\"\"\n",
    "        return K.relu(x, max_value=6.0)\n",
    "\n",
    "\n",
    "    def _conv_block(self, inputs, filters, kernel, strides):\n",
    "        \"\"\"Convolution Block\n",
    "        This function defines a 2D convolution operation with BN and relu6.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "            filters: Integer, the dimensionality of the output space.\n",
    "            kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "                width and height of the 2D convolution window.\n",
    "            strides: An integer or tuple/list of 2 integers,\n",
    "                specifying the strides of the convolution along the width and height.\n",
    "                Can be a single integer to specify the same value for\n",
    "                all spatial dimensions.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "        x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        return Activation(self.relu6)(x)\n",
    "\n",
    "\n",
    "    def _bottleneck(self, inputs, filters, kernel, t, alpha, s, r=False):\n",
    "        \"\"\"Bottleneck\n",
    "        This function defines a basic bottleneck structure.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "            filters: Integer, the dimensionality of the output space.\n",
    "            kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "                width and height of the 2D convolution window.\n",
    "            t: Integer, expansion factor.\n",
    "                t is always applied to the input size.\n",
    "            s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "                of the convolution along the width and height.Can be a single\n",
    "                integer to specify the same value for all spatial dimensions.\n",
    "            alpha: Integer, width multiplier.\n",
    "            r: Boolean, Whether to use the residuals.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "        # Depth\n",
    "        tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "        # Width\n",
    "        cchannel = int(filters * alpha)\n",
    "\n",
    "        x = self._conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "\n",
    "        x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "        x = Activation(self.relu6)(x)\n",
    "\n",
    "        x = Conv2D(cchannel, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "        x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "        if r:\n",
    "            x = Add()([x, inputs])\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _inverted_residual_block(self, inputs, filters, kernel, t, alpha, strides, n):\n",
    "        \"\"\"Inverted Residual Block\n",
    "        This function defines a sequence of 1 or more identical layers.\n",
    "        # Arguments\n",
    "            inputs: Tensor, input tensor of conv layer.\n",
    "            filters: Integer, the dimensionality of the output space.\n",
    "            kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "                width and height of the 2D convolution window.\n",
    "            t: Integer, expansion factor.\n",
    "                t is always applied to the input size.\n",
    "            alpha: Integer, width multiplier.\n",
    "            s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "                of the convolution along the width and height.Can be a single\n",
    "                integer to specify the same value for all spatial dimensions.\n",
    "            n: Integer, layer repeat times.\n",
    "        # Returns\n",
    "            Output tensor.\n",
    "        \"\"\"\n",
    "\n",
    "        x = self._bottleneck(inputs, filters, kernel, t, alpha, strides)\n",
    "\n",
    "        for i in range(1, n):\n",
    "            x = self._bottleneck(x, filters, kernel, t, alpha, 1, True)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def BaseMobileNet(self, inputs, alpha = 1.0):\n",
    "        \"\"\"MobileNetv2\n",
    "        This function defines a MobileNetv2 architectures.\n",
    "        # Arguments\n",
    "            input_shape: An integer or tuple/list of 3 integers, shape\n",
    "                of input tensor.\n",
    "            k: Integer, number of classes.\n",
    "            alpha: Integer, width multiplier, better in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4].\n",
    "        # Returns\n",
    "            MobileNetv2 model.\n",
    "        \"\"\"\n",
    "\n",
    "        first_filters = self._make_divisible(32 * alpha, 8)\n",
    "        x = self._conv_block(inputs, first_filters, (3, 3), strides=(2, 2))\n",
    "\n",
    "        x = self._inverted_residual_block(x, 16, (3, 3), t=1, alpha=alpha, strides=1, n=1)\n",
    "        x = self._inverted_residual_block(x, 24, (3, 3), t=6, alpha=alpha, strides=2, n=2)\n",
    "        x = self._inverted_residual_block(x, 32, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "        x = self._inverted_residual_block(x, 64, (3, 3), t=6, alpha=alpha, strides=2, n=4)\n",
    "        x = self._inverted_residual_block(x, 96, (3, 3), t=6, alpha=alpha, strides=1, n=3)\n",
    "        x = self._inverted_residual_block(x, 160, (3, 3), t=6, alpha=alpha, strides=2, n=3)\n",
    "        x = self._inverted_residual_block(x, 320, (3, 3), t=6, alpha=alpha, strides=1, n=1)\n",
    "\n",
    "        #if alpha > 1.0:\n",
    "            #last_filters = _make_divisible(1280 * alpha, 8)\n",
    "        #else:\n",
    "            #last_filters = 1280\n",
    "\n",
    "        #x = _conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "        #x = GlobalAveragePooling2D()(x)\n",
    "        #x = Reshape((1, 1, last_filters))(x)\n",
    "        #x = Dropout(0.3, name='Dropout')(x)\n",
    "        #x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_race_branch(self, inputs, num_races = 5, alpha = 1.0):\n",
    "        \"\"\"\n",
    "        Used to build the race branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        k = num_races\n",
    "        x = self.BaseMobileNet(inputs, alpha)\n",
    "\n",
    "        if alpha > 1.0:\n",
    "            last_filters = _make_divisible(1280 * alpha, 8)\n",
    "        else:\n",
    "            last_filters = 1280\n",
    "\n",
    "        x = self._conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((1, 1, last_filters))(x)# this line determines end shape maybe?\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "        x = Activation('softmax')(x)#this line might change based on the activation we want, here softmax is fine\n",
    "        #output = Reshape((k,))(x) //We're not returning output here but we DO want to reshape\n",
    "        x = Reshape((k,))(x)\n",
    "        \n",
    "        #i dont think the stuff below this really applies to mobile net. its part of the model rodrigobressan uses, not mobile net.\n",
    "        #x = Flatten()(x)\n",
    "        #x = Dense(128)(x)\n",
    "        #x = Activation(\"relu\")(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dense(num_races)(x)\n",
    "        #x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "        print(type(x))\n",
    "        return x\n",
    "\n",
    "    def build_gender_branch(self, inputs, num_genders=2, alpha = 1.0):\n",
    "        \"\"\"\n",
    "        Used to build the gender branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "        \"\"\"\n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\n",
    "        k = num_genders\n",
    "        x = self.BaseMobileNet(inputs, alpha)\n",
    "        if alpha > 1.0:\n",
    "            last_filters = _make_divisible(1280 * alpha, 8)\n",
    "        else:\n",
    "            last_filters = 1280\n",
    "\n",
    "        x = self._conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((1, 1, last_filters))(x)# this line determines end shape maybe?\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "        x = Activation('softmax')(x)#this line might change based on the activation we want, here should we be using sigmoid?\n",
    "\n",
    "        #output = Reshape((k,))(x) //We're not returning output here but we DO want to reshape\n",
    "        x = Reshape((k,))(x)\n",
    "    \n",
    "        #i dont think the stuff below this really applies to mobile net. its part of the model rodrigobressan uses, not mobile net.\n",
    "        #x = Flatten()(x)\n",
    "        #x = Dense(128)(x)\n",
    "        #x = Activation(\"relu\")(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dense(num_genders)(x)\n",
    "        #x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_age_branch(self, inputs, alpha = 1.0):   \n",
    "        \"\"\"\n",
    "        Used to build the age branch of our face recognition network.\n",
    "        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \n",
    "        followed by the Dense output layer.\n",
    "\n",
    "        \"\"\"\n",
    "        k = 1 #?\n",
    "        x = self.BaseMobileNet(inputs, alpha)\n",
    "\n",
    "        if alpha > 1.0:\n",
    "            last_filters = self._make_divisible(1280 * alpha, 8)\n",
    "        else:\n",
    "            last_filters = 1280\n",
    "\n",
    "        x = self._conv_block(x, last_filters, (1, 1), strides=(1, 1))\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Reshape((1, 1, last_filters))(x)# this line determines end shape maybe?\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "        x = Activation('softmax')(x)#this line might change based on the activation we want, here should we be using linear?\n",
    "\n",
    "        #output = Reshape((k,))(x) //We're not returning output here but we DO want to reshape\n",
    "        x = Reshape((k,))(x)\n",
    "    \n",
    "        #i dont think the stuff below this really applies to mobile net. its part of the model rodrigobressan uses, not mobile net.\n",
    "\n",
    "        #x = Flatten()(x)\n",
    "        #x = Dense(128)(x)\n",
    "        #x = Activation(\"relu\")(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        #x = Dropout(0.5)(x)\n",
    "        #x = Dense(1)(x)\n",
    "        #x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def build_multi_model(self, input_shape): #def MobileNetv2(input_shape, k, alpha=1.0):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        #x = Activation('softmax', name='softmax')(x)\n",
    "        #print(x)\n",
    "        age_branch = self.build_age_branch(inputs)\n",
    "        race_branch = self.build_race_branch(inputs)\n",
    "        gender_branch = self.build_gender_branch(inputs)\n",
    "\n",
    "        model = Model(inputs=inputs, outputs = [age_branch, race_branch, gender_branch], name=\"face_net\")\n",
    "        # plot_model(model, to_file='images/MobileNetv2.png', show_shapes=True)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'keras.engine.keras_tensor.KerasTensor'>\n"
     ]
    }
   ],
   "source": [
    "    #model = MobileNetv2((192, 192, 3), 100, 1.0)  v why 192?\n",
    "    model = MuiltiMobileModel().build_multi_model((192,192,3))\n",
    "    #print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.png'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-766928977a5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1499\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[0;32m   1503\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fp, filename)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;31m# filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.png'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "img = mpimg.imread('model.png')\n",
    "\n",
    "plt.figure(figsize=(40, 30))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}